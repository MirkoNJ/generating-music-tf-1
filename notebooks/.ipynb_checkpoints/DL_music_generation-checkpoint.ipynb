{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b58f0b44",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4571762c",
   "metadata": {},
   "source": [
    "#### Standard library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d4e533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542d2fc5",
   "metadata": {},
   "source": [
    "#### Third party imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95eedb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn import LSTMStateTuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b279895",
   "metadata": {},
   "source": [
    "#### Local imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84f1b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.nikhil.midi_related as midi\n",
    "import modules.nikhil.batch as batch\n",
    "\n",
    "from modules.nikhil.MyFunctions import (\n",
    "    alignXy,\n",
    "    Conditional_Probability_Layer,\n",
    "    Input_Kernel, \n",
    "    getNumberOfBatches,\n",
    "    Loss_Function_1,\n",
    "    Loss_Function_2,\n",
    "    LSTM_Cell,\n",
    "    LSTM_Layer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36d89ce",
   "metadata": {},
   "source": [
    "#### Extensions and autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b29062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b10f44",
   "metadata": {},
   "source": [
    "#### Setting relative directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc8587b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Working_Directory = os.getcwd()\n",
    "Project_Directory = os.path.abspath(os.path.join(Working_Directory,'..'))\n",
    "Music_In_Directory = Project_Directory + \"/data/chopin_midi/\" \n",
    "Output_Directory = Project_Directory + \"/outputs/\"\n",
    "Model_Directory = Output_Directory + \"models/\"\n",
    "Checkpoint_Directory = Model_Directory + \"ckpt/\"\n",
    "Checkpoint_Date_Directory = Checkpoint_Directory + \"20210830/\"\n",
    "Checkpoint_Date_Epoch_Directory = Checkpoint_Date_Directory + \"Long_Train_256\"\n",
    "Music_Out_Directory = Output_Directory + \"midi/\"\n",
    "Music_Out_Genereating_Directory = Music_Out_Directory + \"generated/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0723be7",
   "metadata": {},
   "source": [
    "#### Redefine model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "862b6050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters \n",
    "lowerBound = 21\n",
    "upperBound = 109\n",
    "Midi_low = lowerBound\n",
    "Midi_high = upperBound - 1\n",
    "num_notes = Midi_high + 1 - Midi_low # X.shape[1] = Midi_high + 1 - Midi_low \n",
    "num_timesteps = 16*3*2 \n",
    "input_size = 4\n",
    "keep_prob = 0.5\n",
    "\n",
    "num_t_units = [128, 128] # [200, 200]\n",
    "num_n_units = [64, 64] # [100, 100]\n",
    "dense_units = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3853722d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Graph...\n",
      "Note_State_Expand shape =  (?, 88, ?, 108)\n",
      "Note_State_Batch shape =  (?, 88, ?, 4)\n",
      "Time-wise output shape =  (?, 88, ?, 128)\n",
      "Note-wise output shape =  (?, 88, ?, 64)\n",
      "play_articulate_logit output shape =  (?, 88, ?, 2)\n",
      "velocity output shape =  (?, 88, ?, 1)\n",
      "play_articulate_sampled output shape =  (?, 88, ?, 2)\n",
      "Graph Building Complete\n"
     ]
    }
   ],
   "source": [
    "# Build the Model Graph:\n",
    "tf.reset_default_graph()\n",
    "print('Building Graph...')\n",
    "\n",
    "# Graph Input Placeholders\n",
    "Note_State_Batch = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None, input_size], name= \"Note_State_Batch\")\n",
    "output_keep_prob = tf.placeholder(dtype=tf.float32, shape=(), name= \"output_keep_prob\")\n",
    "\n",
    "#Generate expanded tensor from batch of note state matrices\n",
    "Note_State_Expand = Input_Kernel(Note_State_Batch, \n",
    "                                 Midi_low=Midi_low, \n",
    "                                 Midi_high=Midi_high #,\n",
    "                                 #time_init=time_init\n",
    "                                )\n",
    "Note_State_Expand_aligned, Note_State_Batch_aligned = alignXy(Note_State_Expand, Note_State_Batch)\n",
    "\n",
    "print('Note_State_Expand shape = ', Note_State_Expand.get_shape())\n",
    "print('Note_State_Batch shape = ',  Note_State_Batch.get_shape())\n",
    "\n",
    "# Generate initial state (at t=0) placeholder\n",
    "timewise_state=[]\n",
    "for i in range(len(num_t_units)):\n",
    "    timewise_c=tf.placeholder(dtype=tf.float32, shape=[None, num_t_units[i]]) #None = batch_size * num_notes\n",
    "    timewise_h=tf.placeholder(dtype=tf.float32, shape=[None, num_t_units[i]])\n",
    "    timewise_state.append(LSTMStateTuple(timewise_h, timewise_c))\n",
    "\n",
    "timewise_state=tuple(timewise_state)\n",
    "\n",
    "timewise_cell = LSTM_Cell(num_t_units, output_keep_prob)\n",
    "\n",
    "timewise_out, timewise_state_out = LSTM_Layer(input_data=Note_State_Expand_aligned,\n",
    "                                              state_init=timewise_state,\n",
    "                                              cell = timewise_cell,\n",
    "                                              time_or_note=\"time\")\n",
    "\n",
    "print('Time-wise output shape = ', timewise_out.get_shape())\n",
    "# print('Time-wise state shape = ', timewise_state_out)\n",
    "\n",
    "#LSTM Note Wise Graph\n",
    "\n",
    "# Generate initial state (at n=0) placeholder\n",
    "notewise_state=[]\n",
    "for i in range(len(num_n_units)):\n",
    "    notewise_c=tf.placeholder(dtype=tf.float32, shape=[None, num_n_units[i]]) #None = batch_size * num_timesteps\n",
    "    notewise_h=tf.placeholder(dtype=tf.float32, shape=[None, num_n_units[i]])\n",
    "    notewise_state.append(LSTMStateTuple(notewise_h, notewise_c))\n",
    "\n",
    "notewise_state=tuple(notewise_state)\n",
    "\n",
    "notewise_cell = LSTM_Cell(num_n_units, output_keep_prob)\n",
    "\n",
    "notewise_out, notewise_state_out =  LSTM_Layer(input_data=timewise_out,\n",
    "                                               state_init=notewise_state,\n",
    "                                               cell=notewise_cell,\n",
    "                                               time_or_note=\"note\")\n",
    "\n",
    "print('Note-wise output shape = ', notewise_out.get_shape())\n",
    "# print('Note-wise state shape = ', notewise_state_out)\n",
    "\n",
    "output_1, output_2, output_3 = Conditional_Probability_Layer(notewise_out, dense_units=dense_units)\n",
    "\n",
    "print('play_articulate_logit output shape = ', output_1.get_shape())\n",
    "print('velocity output shape = ', output_2.get_shape()) \n",
    "print('play_articulate_sampled output shape = ', output_3.get_shape())\n",
    "\n",
    "print('Graph Building Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf3a2b6",
   "metadata": {},
   "source": [
    "### MIDI generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59be6fdc",
   "metadata": {},
   "source": [
    "#### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "247c9264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a song with 144 timesteps corresponding to 4 bars\n"
     ]
    }
   ],
   "source": [
    "primer = False #'chop6401'\n",
    "n_bars = 4\n",
    "batch_size_gen = 4\n",
    "n_time_steps_per_sixtheenth = 3\n",
    "max_sixteenth_index = 12 \n",
    "n_time_steps_ber_bar = max_sixteenth_index * n_time_steps_per_sixtheenth\n",
    "num_timesteps =  n_time_steps_ber_bar * n_bars \n",
    "\n",
    "t_gen = n_bars * n_time_steps_ber_bar\n",
    "print(\"Create a song with\", t_gen, \"timesteps corresponding to\", n_bars, \"bars\")\n",
    "\n",
    "if primer:\n",
    "    primer = midi.midiToNoteStateMatrix(Music_In_Directory + primer + \".mid\", \n",
    "                                        verbose = False, \n",
    "                                        verbose_ts = False) \n",
    "    sixteenth_index = [b[0][3] for b in  primer]\n",
    "    max_sixteenth_index = max(sixteenth_index)\n",
    "    n_time_steps_ber_bar = max_sixteenth_index * n_time_steps_per_sixtheenth\n",
    "    num_timesteps =  n_time_steps_ber_bar * (n_bars // 2) \n",
    "    batch_input_state, start_old = batch.getPieceBatch2(primer, \n",
    "                                                        num_time_steps = num_timesteps - 1, \n",
    "                                                        batch_size = batch_size_gen,\n",
    "                                                        start_old = 0) \n",
    "    notes_gen_initial = batch_input_state[:,:,-(num_timesteps):,:]\n",
    "    notes_gen = notes_gen_initial\n",
    "    name = \"primer\"\n",
    "else:\n",
    "    num_timesteps =  n_time_steps_ber_bar * (n_bars // 2) \n",
    "    notes_gen_initial = np.zeros((batch_size_gen, num_notes, num_timesteps, 3))\n",
    "    beats_initial = [int(t / n_time_steps_per_sixtheenth) % int(n_time_steps_ber_bar / n_time_steps_per_sixtheenth) + 1 for t in range(num_timesteps)]\n",
    "    beats_initial = np.transpose(np.array(beats_initial, ndmin = 4), (0,1,3,2))\n",
    "    beats_initial = np.tile(beats_initial, [batch_size_gen,num_notes,1,1])\n",
    "    notes_gen_initial = np.concatenate([notes_gen_initial, beats_initial], axis=3)\n",
    "    # Initial States\n",
    "    notes_gen = notes_gen_initial\n",
    "    name = \"from scratch\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fba4e2",
   "metadata": {},
   "source": [
    "#### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9f4f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "timewise_state_val=[]\n",
    "for i in range(len(num_t_units)):\n",
    "    c = np.zeros((batch_size_gen*num_notes, num_t_units[i])) #start first time step with zero state in LSTM time cells\n",
    "    h = np.zeros((batch_size_gen*num_notes, num_t_units[i]))\n",
    "    timewise_state_val.append(LSTMStateTuple(h, c))\n",
    "        \n",
    "notewise_state_val=[]\n",
    "for i in range(len(num_n_units)):\n",
    "    c = np.zeros((batch_size_gen*(num_timesteps_initial-1), num_n_units[i])) #start every batch with zero state in LSTM time cells\n",
    "    h = np.zeros((batch_size_gen*(num_timesteps_initial-1), num_n_units[i]))\n",
    "    notewise_state_val.append(LSTMStateTuple(h, c))\n",
    "        \n",
    "notes_gen_arr=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9375812",
   "metadata": {},
   "source": [
    "#### Genereate new MIDI files from scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc70fb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from: /home/mirko/Documents/FHWN/MA/master_thesis/code/tf1/outputs/models/ckpt/20210830/Long_Train_256\n",
      "INFO:tensorflow:Restoring parameters from /home/mirko/Documents/FHWN/MA/master_thesis/code/tf1/outputs/models/ckpt/20210830/Long_Train_256\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    print(\"Load the model from: {}\".format(Checkpoint_Date_Epoch_Directory))\n",
    "    saver.restore(sess, Checkpoint_Date_Epoch_Directory)\n",
    "    \n",
    "\n",
    "    for t in range(t_gen):\n",
    "\n",
    "        beat = int(t / n_time_steps_per_sixtheenth) % int(n_time_steps_ber_bar / n_time_steps_per_sixtheenth) + 1\n",
    "        \n",
    "        feed_dict = {Note_State_Batch: notes_gen[:,:,-(num_timesteps_initial):,:], \n",
    "                     timewise_state: timewise_state_val, \n",
    "                     notewise_state: notewise_state_val, \n",
    "                     output_keep_prob: keep_prob}  \n",
    "        \n",
    "        timewise_state_val, velocity_gen, notes_a_p, Note_State_Batch_result, Note_State_Expand_result = sess.run(\n",
    "            [timewise_state_out, output_2, output_3, Note_State_Batch_aligned, Note_State_Expand_aligned],\n",
    "            feed_dict = feed_dict)\n",
    "        \n",
    "        # new_note = np.concatenate([notes_a_p, velocity_gen, Note_State_Batch_result[:,:,:,3:4]], axis=-1)\n",
    "        new_note = np.concatenate([notes_a_p[:,:,-1:,:], velocity_gen[:,:,-1:,:]], axis=-1)\n",
    "        new_note_p   = new_note[:,:,:,0]\n",
    "        new_note_a   = new_note[:,:,:,1] * new_note[:,:,:,0]\n",
    "        new_note_vel = new_note[:,:,:,2] * new_note[:,:,:,0]\n",
    "        new_note_beat = np.zeros((batch_size_gen, num_notes, 1), dtype=np.float32)\n",
    "        new_note_beat.fill(beat)\n",
    "        new_note = np.stack([new_note_p, new_note_a, new_note_vel, new_note_beat], axis=-1)\n",
    "        notes_gen = np.concatenate([notes_gen, new_note], axis=2)\n",
    "        \n",
    "        if t == 0 and primer:\n",
    "            current_time_str = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "            for i in range(batch_size_gen):\n",
    "                midi.generate_audio(batch_input_state[i:(i+1),:,:,:], \n",
    "                                    Music_Out_Genereating_Directory + current_time_str[:-7] + '/',\n",
    "                                    'generated_batch_' + str(i) + '_primer', \n",
    "                                    verbose = False)\n",
    "            prediction = np.concatenate([notes_a_p, velocity_gen, Note_State_Batch_result[:,:,:,3:4]], axis=-1)\n",
    "            for i in range(batch_size_gen):\n",
    "                midi.generate_audio(prediction[i:(i+1),:,:,:], \n",
    "                                    Music_Out_Genereating_Directory + current_time_str[:-7] + '/',\n",
    "                                    'generated_batch_' + str(i) + '_primer_predicted', \n",
    "                                    verbose = False)\n",
    "        if t == (t_gen - 3):\n",
    "            current_time_str = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "            if primer:\n",
    "                for i in range(batch_size_gen):\n",
    "                    midi.generate_audio(notes_gen[i:(i+1),:,:,:], \n",
    "                                        Music_Out_Genereating_Directory + current_time_str[:-7] + '/',\n",
    "                                        'generated_batch_' + str(i) + '_from_primer', \n",
    "                                        verbose = False)\n",
    "            else:\n",
    "                for i in range(batch_size_gen):\n",
    "                    midi.generate_audio(notes_gen[i:(i+1),:,:,:], \n",
    "                                        Music_Out_Genereating_Directory + current_time_str[:-7] + '/',\n",
    "                                        'generated_batch_' + str(i) + '_from_scratch', \n",
    "                                        verbose = False)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
