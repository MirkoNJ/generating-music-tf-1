{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import os\n",
    "import pdb\n",
    "import random\n",
    "import time\n",
    "from tempfile import TemporaryFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third party imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib.rnn import BasicLSTMCell, LSTMStateTuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.nikhil.midi_related as midi\n",
    "import modules.nikhil.batch as batch\n",
    "\n",
    "from modules.nikhil.MyFunctions import (\n",
    "    alignXy,\n",
    "    Conditional_Probability_Layer,\n",
    "    Input_Kernel, \n",
    "    getNumberOfBatches,\n",
    "    Loss_Function_1,\n",
    "    Loss_Function_2,\n",
    "    LSTM_Cell,\n",
    "    LSTM_Layer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extensions and autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting relative directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Working_Directory = os.getcwd()\n",
    "Project_Directory = os.path.abspath(os.path.join(Working_Directory,'..'))\n",
    "Music_In_Directory = Project_Directory + \"/data/\" \n",
    "Output_Directory = Project_Directory + \"/outputs/\"\n",
    "Model_Directory = Output_Directory + \"models/\"\n",
    "Music_Out_Directory = Output_Directory + \"midi/\"\n",
    "Music_Out_Train_Directory = Music_Out_Directory + \"train/\"\n",
    "Checkpoint_Directory = Model_Directory + \"ckpt/\"\n",
    "Numpy_Directory = Model_Directory + \"np/\"\n",
    "\n",
    "Midi_Directories = [\n",
    "    #\"albeniz\", \n",
    "    #\"beeth\",\n",
    "    #\"borodin\",\n",
    "    #\"brahms\",\n",
    "    #\"burgm\",\n",
    "    #\"chopin\", \n",
    "    \"chopin_midi\",\n",
    "    #\"debussy\", \n",
    "    #\"granados\", \n",
    "    #\"grieg\", \n",
    "    #\"haydn\", \n",
    "    #\"liszt\", \n",
    "    #\"mendelssohn\", \n",
    "    #\"mozart\", \n",
    "    #\"muss\", \n",
    "    #\"schubert\", \n",
    "    #\"schumann\", \n",
    "    \"tschai\"\n",
    "] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pieces (i.e. import midi files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First checkt that importing single midi (i.e. Beethoven's Fuer Elise) works\n",
    "elise = midi.midiToNoteStateMatrix(Music_In_Directory + \"beeth/elise.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded chop0601\n",
      "Loaded chop0602\n",
      "Loaded chop0603\n",
      "Loaded chop0701\n",
      "Loaded chop0702\n",
      "Loaded chop0901\n",
      "Loaded chop0902\n",
      "Loaded chop0903\n",
      "Loaded chop1001\n",
      "Loaded chop1002\n",
      "Loaded chop1003\n",
      "Loaded chop1004\n",
      "Loaded chop1005\n",
      "Loaded chop1007\n",
      "Loaded chop1012\n",
      "Loaded chop1501\n",
      "Loaded chop1502\n",
      "Loaded chop1503\n",
      "Loaded chop1800\n",
      "Loaded chop2300\n",
      "Loaded chop2501\n",
      "Loaded chop2502\n",
      "Loaded chop2503\n",
      "Loaded chop2504\n",
      "Loaded chop2506\n",
      "Loaded chop2507\n",
      "Loaded chop2511\n",
      "Loaded chop2512\n",
      "Loaded chop2701\n",
      "Loaded chop2702\n",
      "Loaded chop2801\n",
      "Loaded chop2802\n",
      "Loaded chop2803\n",
      "Loaded chop2804\n",
      "Loaded chop2805\n",
      "Loaded chop2806\n",
      "Loaded chop2807\n",
      "Loaded chop2808\n",
      "Loaded chop2809\n",
      "Loaded chop2810\n",
      "Loaded chop2811\n",
      "Loaded chop2812\n",
      "Loaded chop2813\n",
      "Loaded chop2814\n",
      "Loaded chop2815\n",
      "Loaded chop2816\n",
      "Loaded chop2817\n",
      "Loaded chop2818\n",
      "Loaded chop2819\n",
      "Loaded chop2820\n",
      "Loaded chop2821\n",
      "Loaded chop2822\n",
      "Loaded chop2823\n",
      "Loaded chop2824\n",
      "Loaded chop3002\n",
      "Loaded chop3100\n",
      "Loaded chop3202\n",
      "Loaded chop3302\n",
      "Loaded chop3304\n",
      "Loaded chop3402\n",
      "Loaded chop3502\n",
      "Loaded chop3503\n",
      "Loaded chop3504\n",
      "Loaded chop3701\n",
      "Loaded chop3702\n",
      "Loaded chop3800\n",
      "Loaded chop4001\n",
      "Loaded chop4002\n",
      "Loaded chop4200\n",
      "Loaded chop4700\n",
      "Loaded chop4801\n",
      "Loaded chop4802\n",
      "Loaded chop5200\n",
      "Loaded chop5300\n",
      "Loaded chop5501\n",
      "Loaded chop5502\n",
      "Loaded chop5801\n",
      "Loaded chop5802\n",
      "Loaded chop5803\n",
      "Loaded chop5804\n",
      "Loaded chop5902\n",
      "Loaded chop6201\n",
      "Loaded chop6202\n",
      "Loaded chop6303\n",
      "Loaded chop6401\n",
      "Loaded chop6402\n",
      "Loaded chop6600\n",
      "Loaded chop6701\n",
      "Loaded chop6702\n",
      "Loaded chop6704\n",
      "Loaded chop6802\n",
      "Loaded chop6901\n",
      "Loaded chop6902\n",
      "Loaded chop7002\n",
      "Loaded chop7201\n",
      "Loading directory chopin_midi took 84.759s\n",
      "Loaded ty_april\n",
      "Loaded ty_august\n",
      "Loaded ty_dezember\n",
      "Loaded ty_februar\n",
      "Loaded ty_januar\n",
      "Loaded ty_juli\n",
      "Loaded ty_juni\n",
      "Loaded ty_maerz\n",
      "Loaded ty_mai\n",
      "Loaded ty_november\n",
      "Loaded ty_oktober\n",
      "Loaded ty_september\n",
      "Loading directory tschai took 9.206s\n",
      "Number of total pieces =  107\n",
      "Loading all pieces took 93.965s\n"
     ]
    }
   ],
   "source": [
    "# Import all Midi data\n",
    "min_time_steps = 128 # only files with at least this many 48th note steps are saved\n",
    "lowerBound = 21\n",
    "upperBound = 109\n",
    "\n",
    "all_pieces = {}\n",
    "chopin_only_pieces = {}\n",
    "piano_midi_only_pieces = {}\n",
    "\n",
    "start_time_loading = time.time()\n",
    "time_loading_old = start_time_loading\n",
    "\n",
    "# Gather the pieces from the specified directory\n",
    "for f in range(len(Midi_Directories)):\n",
    "    Training_Midi_Folder = Music_In_Directory + Midi_Directories[f]\n",
    "    if Midi_Directories[f] == 'chopin_midi':\n",
    "        chopin_only_pieces = {**chopin_only_pieces, **midi.loadPieces(Training_Midi_Folder,\n",
    "                                                                      min_time_steps,\n",
    "                                                                      lowerBound, \n",
    "                                                                      upperBound,\n",
    "                                                                      verbose=False,\n",
    "                                                                      verbose_name=True)}\n",
    "    else: \n",
    "        piano_midi_only_pieces = {**piano_midi_only_pieces, **midi.loadPieces(Training_Midi_Folder,\n",
    "                                                                              min_time_steps,\n",
    "                                                                              lowerBound, \n",
    "                                                                              upperBound,\n",
    "                                                                              verbose=False,\n",
    "                                                                              verbose_name=True)}\n",
    "    time_loading_new = time.time()\n",
    "    duration = time_loading_new - time_loading_old\n",
    "    time_loading_old = time_loading_new\n",
    "    print('Loading directory ' + Midi_Directories[f] + ' took ' + str(round(duration, 3)) + 's' )\n",
    "\n",
    "all_pieces = {**chopin_only_pieces, **piano_midi_only_pieces}\n",
    "end_time_loading = time.time()\n",
    "\n",
    "print('Number of total pieces = ', len(all_pieces))    \n",
    "print('Loading all pieces took ' +  str(round(end_time_loading - start_time_loading, 3)) + 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_time_signatures = [16]\n",
    "odd_time_signatures = [12]\n",
    "sel_time_signautres = even_time_signatures\n",
    "#sel_time_signautres = odd_time_signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  'incorrect' Chopin pieces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chopin pieces loaded =  95\n"
     ]
    }
   ],
   "source": [
    "print('Number of Chopin pieces loaded = ', len(chopin_only_pieces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 1, 6: 3, 8: 2, 12: 37, 16: 31, 17: 1, 19: 1, 24: 6, 28: 1, 36: 1, 40: 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check time signature occurences\n",
    "time_signatures = []\n",
    "verbose = False #True\n",
    "keys = list(chopin_only_pieces.keys())\n",
    "for k in keys:\n",
    "    piece = chopin_only_pieces[str(k)]\n",
    "    time_signature = max([b[0][3] for b in  piece])\n",
    "    if str(k) in midi.EXACT_FILES:\n",
    "        time_signatures.append(time_signature)\n",
    "    if verbose:\n",
    "        print(\"Piece: {}\".format(k) + \"  Time signature: {}\".format(time_signature))\n",
    "time_signatures = np.array(time_signatures)\n",
    "unique, counts = np.unique(time_signatures, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{16: 31}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only include pieces which were not recoreded (i.e. which MIDI files are exact) and are in (2/4 and 4/4) or in (3/4)\n",
    "time_signatures = []\n",
    "verbose = False #True\n",
    "chopin_pieces_filtered = chopin_only_pieces.copy()\n",
    "keys = list(chopin_pieces_filtered.keys())\n",
    "\n",
    "for k in keys:\n",
    "        piece = chopin_pieces_filtered[str(k)]\n",
    "        time_signature = max([b[0][3] for b in  piece])\n",
    "        if not ((time_signature in sel_time_signautres) and str(k) in midi.EXACT_FILES) :\n",
    "            chopin_pieces_filtered.pop(k)\n",
    "        else:\n",
    "            time_signatures.append(time_signature)\n",
    "        if verbose:\n",
    "            print(\"Piece: {}\".format(k) + \"  Time signature: {}\".format(time_signature))\n",
    "time_signatures = np.array(time_signatures)\n",
    "unique, counts = np.unique(time_signatures, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pieces by Chopin left after filtering =  31\n"
     ]
    }
   ],
   "source": [
    "print('Number of pieces by Chopin left after filtering = ', len(chopin_pieces_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Piano Midi pieces by 3/4 or 4/4 measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Piano Midi pieces loaded =  12\n"
     ]
    }
   ],
   "source": [
    "print('Number of Piano Midi pieces loaded = ', len(piano_midi_only_pieces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8: 2, 12: 4, 16: 5, 18: 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check time signature occurences\n",
    "time_signatures = []\n",
    "verbose = False #True\n",
    "keys = list(piano_midi_only_pieces.keys())\n",
    "for k in keys:\n",
    "    piece = piano_midi_only_pieces[str(k)]\n",
    "    time_signature = max([b[0][3] for b in  piece])\n",
    "    time_signatures.append(time_signature)\n",
    "    if verbose:\n",
    "        print(\"Piece: {}\".format(k) + \"  Time signature: {}\".format(time_signature))\n",
    "time_signatures = np.array(time_signatures)\n",
    "unique, counts = np.unique(time_signatures, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter training pieces by selected time signature\n",
    "piano_midi_pieces_filtered = piano_midi_only_pieces.copy()\n",
    "piano_midi_pieces_remaining = piano_midi_only_pieces.copy()\n",
    "keys = list(piano_midi_only_pieces.keys())\n",
    "verbose = False\n",
    "\n",
    "for k in keys:\n",
    "    piece = piano_midi_only_pieces[str(k)]\n",
    "    time_signature = int(max([b[0][3] for b in  piece]))\n",
    "    if not (time_signature in sel_time_signautres):\n",
    "        piano_midi_pieces_filtered.pop(k)\n",
    "    else:\n",
    "        piano_midi_pieces_remaining.pop(k)\n",
    "    if verbose:\n",
    "        print(\"Piece: {}\".format(k) + \"  Time signature: {}\".format(time_signature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Piano Midi pieces left after filtering =  5\n"
     ]
    }
   ],
   "source": [
    "print('Number of Piano Midi pieces left after filtering = ', len(piano_midi_pieces_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Validation pieces split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pieces relevant for training and validation\n",
    "#pieces_tmp = piano_midi_pieces_filtered.copy()\n",
    "pieces_tmp = chopin_pieces_filtered.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up memory\n",
    "def free_memory():\n",
    "    all_pieces.clear()\n",
    "    chopin_only_pieces.clear()\n",
    "    piano_midi_only_pieces.clear()\n",
    "    piano_midi_pieces_filtered.clear()\n",
    "    piano_midi_pieces_remaining.clear()\n",
    "    pieces_tmp.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Either select one validation and one training piece or \n",
    "# set aside a random set of pieces for validation purposes\n",
    "n_subset = 30\n",
    "#selection = 'single_piece' \n",
    "#selection = 'subset'\n",
    "selection = 'all'\n",
    "\n",
    "random.seed(1337)\n",
    "if selection == 'single_piece':\n",
    "    validation_pieces = copy.deepcopy({'chop2803' : all_pieces['chop2803']})\n",
    "    training_pieces   = copy.deepcopy({'chop2804' : all_pieces['chop2804']})\n",
    "    free_memory()\n",
    "elif selection == 'subset' or selection == 'all':\n",
    "    if selection == 'subset':\n",
    "        training_pieces = copy.deepcopy({k: pieces_tmp[k] for k in random.sample(list(pieces_tmp.keys()), n_subset)})\n",
    "        free_memory()\n",
    "    elif selection == 'all':\n",
    "        training_pieces = pieces_tmp.copy()\n",
    "    num_validation_pieces = len(training_pieces) // 10\n",
    "\n",
    "    validation_pieces={}\n",
    "    for v in range(num_validation_pieces):\n",
    "        index = random.choice(list(training_pieces.keys()))\n",
    "        validation_pieces[index] = training_pieces.pop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training   pieces =  28\n",
      "Number of validation pieces =  3\n"
     ]
    }
   ],
   "source": [
    "print('Number of training   pieces = ', len(training_pieces))    \n",
    "print('Number of validation pieces = ', len(validation_pieces))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that features (X) and lables (y) generation work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions y: (sample_size, num_notes, num_timesteps, play_articulate_velocity) =  (16, 88, 96, 4)\n",
      "Dimensions X: (sample_size, num_notes, num_timesteps, feature_dim             ) =  (16, 88, 96, 108)\n"
     ]
    }
   ],
   "source": [
    "# Generate sample Note State Matrix for dimension measurement and numerical checking purposes\n",
    "\n",
    "y = tf.convert_to_tensor(batch.getPieceBatch(training_pieces, # 16\n",
    "                                             batch_size = 16,\n",
    "                                             num_time_steps = 16*3*2), \n",
    "                         dtype=tf.float32) \n",
    "X = Input_Kernel(y, Midi_low = lowerBound, Midi_high = upperBound - 1)\n",
    "X, y = alignXy(X,y)\n",
    "\n",
    "print('Dimensions y: (sample_size, num_notes, num_timesteps, play_articulate_velocity) = ', y.shape)\n",
    "print('Dimensions X: (sample_size, num_notes, num_timesteps, feature_dim             ) = ', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Midi_low = lowerBound\n",
    "Midi_high = upperBound - 1\n",
    "num_notes = Midi_high + 1 - Midi_low # X.shape[1] = Midi_high + 1 - Midi_low \n",
    "num_timesteps = 16*3*2 \n",
    "input_size = 4\n",
    "keep_prob = 0.5\n",
    "\n",
    "num_t_units = [128, 128] # [200, 200]\n",
    "num_n_units = [64, 64] # [100, 100]\n",
    "dense_units = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start building of model graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Graph...\n"
     ]
    }
   ],
   "source": [
    "# Build the Model Graph:\n",
    "tf.reset_default_graph()\n",
    "print('Building Graph...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note_State_Expand shape =  (?, 88, ?, 108)\n",
      "Note_State_Batch shape =  (?, 88, ?, 4)\n"
     ]
    }
   ],
   "source": [
    "# Graph Input Placeholders\n",
    "Note_State_Batch = tf.placeholder(dtype=tf.float32, shape=[None, num_notes, None, input_size], name= \"Note_State_Batch\")\n",
    "output_keep_prob = tf.placeholder(dtype=tf.float32, shape=(), name= \"output_keep_prob\")\n",
    "\n",
    "#Generate expanded tensor from batch of note state matrices\n",
    "Note_State_Expand = Input_Kernel(Note_State_Batch, \n",
    "                                 Midi_low=Midi_low, \n",
    "                                 Midi_high=Midi_high #,\n",
    "                                 #time_init=time_init\n",
    "                                )\n",
    "Note_State_Expand_aligned, Note_State_Batch_aligned = alignXy(Note_State_Expand, Note_State_Batch)\n",
    "\n",
    "print('Note_State_Expand shape = ', Note_State_Expand.get_shape())\n",
    "print('Note_State_Batch shape = ',  Note_State_Batch.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timewise LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-wise output shape =  (?, 88, ?, 128)\n"
     ]
    }
   ],
   "source": [
    "# Generate initial state (at t=0) placeholder\n",
    "timewise_state=[]\n",
    "for i in range(len(num_t_units)):\n",
    "    timewise_c=tf.placeholder(dtype=tf.float32, shape=[None, num_t_units[i]]) #None = batch_size * num_notes\n",
    "    timewise_h=tf.placeholder(dtype=tf.float32, shape=[None, num_t_units[i]])\n",
    "    timewise_state.append(LSTMStateTuple(timewise_h, timewise_c))\n",
    "\n",
    "timewise_state=tuple(timewise_state)\n",
    "\n",
    "timewise_cell = LSTM_Cell(num_t_units, output_keep_prob)\n",
    "\n",
    "timewise_out, timewise_state_out = LSTM_Layer(input_data=Note_State_Expand_aligned,\n",
    "                                              state_init=timewise_state,\n",
    "                                              cell = timewise_cell,\n",
    "                                              time_or_note=\"time\")\n",
    "\n",
    "print('Time-wise output shape = ', timewise_out.get_shape())\n",
    "# print('Time-wise state shape = ', timewise_state_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notewise LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note-wise output shape =  (?, 88, ?, 64)\n"
     ]
    }
   ],
   "source": [
    "#LSTM Note Wise Graph\n",
    "\n",
    "# Generate initial state (at n=0) placeholder\n",
    "notewise_state=[]\n",
    "for i in range(len(num_n_units)):\n",
    "    notewise_c=tf.placeholder(dtype=tf.float32, shape=[None, num_n_units[i]]) #None = batch_size * num_timesteps\n",
    "    notewise_h=tf.placeholder(dtype=tf.float32, shape=[None, num_n_units[i]])\n",
    "    notewise_state.append(LSTMStateTuple(notewise_h, notewise_c))\n",
    "\n",
    "notewise_state=tuple(notewise_state)\n",
    "\n",
    "notewise_cell = LSTM_Cell(num_n_units, output_keep_prob)\n",
    "\n",
    "notewise_out, notewise_state_out =  LSTM_Layer(input_data=timewise_out,\n",
    "                                               state_init=notewise_state,\n",
    "                                               cell=notewise_cell,\n",
    "                                               time_or_note=\"note\")\n",
    "\n",
    "print('Note-wise output shape = ', notewise_out.get_shape())\n",
    "# print('Note-wise state shape = ', notewise_state_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate conditional probabilty using dense layers to generate Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play_articulate_logit output shape =  (?, 88, ?, 2)\n",
      "velocity output shape =  (?, 88, ?, 1)\n",
      "play_articulate_sampled output shape =  (?, 88, ?, 2)\n"
     ]
    }
   ],
   "source": [
    "output_1, output_2, output_3 = Conditional_Probability_Layer(notewise_out, dense_units=dense_units)\n",
    "\n",
    "print('play_articulate_logit output shape = ', output_1.get_shape())\n",
    "print('velocity output shape = ', output_2.get_shape()) \n",
    "print('play_articulate_sampled output shape = ', output_3.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finished building of model graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Building Complete\n"
     ]
    }
   ],
   "source": [
    "print('Graph Building Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function and Optimizer\n",
    "alpha = 0.01 \n",
    "loss_p_a, log_likelihood = Loss_Function_1(Note_State_Batch_aligned, output_1)\n",
    "loss_velocity = Loss_Function_2(Note_State_Batch_aligned, output_2)\n",
    "loss = loss_p_a + alpha * 1 / 127 * tf.sqrt(loss_velocity)\n",
    "optimizer = tf.train.AdadeltaOptimizer(learning_rate = 1, epsilon=1e-04).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF1 specific parameters \n",
    "restore_model_name = 'Long_Train_256'\n",
    "save_model_name = 'Long_Train_256_plus_chopin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time_str = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Training parameters\n",
    "\n",
    "epochs = 16\n",
    "batch_size = 2\n",
    "epoch_save_list = [1, 2, 4, 8, 16]\n",
    "\n",
    "\n",
    "\n",
    "n_train_batches = getNumberOfBatches(training_pieces, batch_size, num_timesteps)\n",
    "n_val_batches = getNumberOfBatches(validation_pieces, batch_size, num_timesteps)\n",
    "\n",
    "# Values for loss, metric and confusion matrix\n",
    "train_loss_p_a_array   = np.full((epochs, n_train_batches), 10.0)\n",
    "train_loss_vel_array   = np.full((epochs, n_train_batches), 10.0)\n",
    "train_metric_p_a_array = np.full((epochs, n_train_batches), 10.0)\n",
    "train_metric_vel_array = np.full((epochs, n_train_batches), 10.0)\n",
    "val_loss_p_a_array     = np.full((epochs, n_val_batches), 10.0)\n",
    "val_loss_vel_array     = np.full((epochs, n_val_batches), 10.0)\n",
    "val_metric_p_a_array   = np.full((epochs, n_val_batches), 10.0)\n",
    "val_metric_vel_array   = np.full((epochs, n_val_batches), 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 56)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(n_train_batches, n_val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the model from: Long_Train_256\n",
      "INFO:tensorflow:Restoring parameters from /home/mirko/Documents/FHWN/MA/master_thesis/code/tf1/outputs/models/ckpt/20210924/Long_Train_256/Long_Train_256\n",
      "Start of Epoch [1/16]\n",
      "\n",
      "\n",
      "Training batch: 889/889\n",
      "Validation batch: 56/56\n",
      "Training   Loss p_a: 0.03239194995171576\n",
      "Validation Loss p_a: 0.03505189804958978\n",
      "Training   Loss vel: 473.43345810296967\n",
      "Validation Loss vel: 291.2471008300781\n",
      "\n",
      "Time: 782.664s\n",
      "Start of Epoch [2/16]\n",
      "\n",
      "\n",
      "Training batch: 889/889\n",
      "Validation batch: 56/56\n",
      "Training   Loss p_a: 0.03113548939207441\n",
      "Validation Loss p_a: 0.034764644323981235\n",
      "Training   Loss vel: 460.3421580826338\n",
      "Validation Loss vel: 295.2358407974243\n",
      "\n",
      "Time: 773.655s\n",
      "Start of Epoch [3/16]\n",
      "\n",
      "\n",
      "Training batch: 889/889\n",
      "Validation batch: 56/56\n",
      "Training   Loss p_a: 0.030519284666762073\n",
      "Validation Loss p_a: 0.034619370342365334\n",
      "Training   Loss vel: 453.4327190901217\n",
      "Validation Loss vel: 293.3595511572702\n",
      "\n",
      "Time: 772.218s\n",
      "Start of Epoch [4/16]\n",
      "\n",
      "\n",
      "Training batch: 889/889\n",
      "Validation batch: 56/56\n",
      "Training   Loss p_a: 0.030020218438922486\n",
      "Validation Loss p_a: 0.034620764232905846\n",
      "Training   Loss vel: 447.1762069170065\n",
      "Validation Loss vel: 287.9533168247768\n",
      "\n",
      "Time: 770.943s\n",
      "Start of Epoch [5/16]\n",
      "\n",
      "\n",
      "Training batch: 889/889\n",
      "Validation batch: 56/56\n",
      "Training   Loss p_a: 0.029595122972756824\n",
      "Validation Loss p_a: 0.03520389227196574\n",
      "Training   Loss vel: 443.7130176986162\n",
      "Validation Loss vel: 293.12220873151506\n",
      "\n",
      "Time: 772.667s\n",
      "Start of Epoch [6/16]\n",
      "\n",
      "\n",
      "Training batch: 889/889\n",
      "Validation batch: 56/56\n",
      "Training   Loss p_a: 0.029267263017318246\n",
      "Validation Loss p_a: 0.035106344580916424\n",
      "Training   Loss vel: 439.9775883617766\n",
      "Validation Loss vel: 291.6728835787092\n",
      "\n",
      "Time: 771.666s\n",
      "Start of Epoch [7/16]\n",
      "\n",
      "\n",
      "Training batch: 889/889\n",
      "Validation batch: 56/56\n",
      "Training   Loss p_a: 0.028971260044769843\n",
      "Validation Loss p_a: 0.034942216805315444\n",
      "Training   Loss vel: 438.0082118588974\n",
      "Validation Loss vel: 292.0456502096994\n",
      "\n",
      "Time: 771.863s\n",
      "Start of Epoch [8/16]\n",
      "\n",
      "\n",
      "Training batch: 889/889\n",
      "Validation batch: 56/56\n",
      "Training   Loss p_a: 0.028718408279925483\n",
      "Validation Loss p_a: 0.03553913613515241\n",
      "Training   Loss vel: 434.7934837727498\n",
      "Validation Loss vel: 294.53665501730785\n",
      "\n",
      "Time: 771.867s\n",
      "Start of Epoch [9/16]\n",
      "\n",
      "\n",
      "Training batch: 889/889\n",
      "Validation batch: 56/56\n",
      "Training   Loss p_a: 0.028409787482520224\n",
      "Validation Loss p_a: 0.035625158343464136\n",
      "Training   Loss vel: 432.12365713216053\n",
      "Validation Loss vel: 293.5319615772792\n",
      "\n",
      "Time: 772.874s\n",
      "Start of Epoch [10/16]\n",
      "\n",
      "\n",
      "Training batch: 889/889\n",
      "Validation batch: 56/56\n",
      "Training   Loss p_a: 0.028174895945102547\n",
      "Validation Loss p_a: 0.03535202641173133\n",
      "Training   Loss vel: 430.65872826163223\n",
      "Validation Loss vel: 293.714364188058\n",
      "\n",
      "Time: 771.398s\n",
      "Start of Epoch [11/16]\n",
      "\n",
      "\n",
      "Training batch: 889/889\n",
      "Validation batch: 56/56\n",
      "Training   Loss p_a: 0.027914337910234056\n",
      "Validation Loss p_a: 0.03552250035240182\n",
      "Training   Loss vel: 429.054436734074\n",
      "Validation Loss vel: 291.3425906045096\n",
      "\n",
      "Time: 771.932s\n",
      "Start of Epoch [12/16]\n",
      "\n",
      "\n",
      "Training batch: 889/889\n",
      "Validation batch: 56/56\n",
      "Training   Loss p_a: 0.027703627930373724\n",
      "Validation Loss p_a: 0.035481433650212627\n",
      "Training   Loss vel: 427.81413550103343\n",
      "Validation Loss vel: 293.0700190407889\n",
      "\n",
      "Time: 771.939s\n",
      "Start of Epoch [13/16]\n",
      "\n",
      "\n",
      "Training batch: 889/889\n",
      "Validation batch: 56/56\n",
      "Training   Loss p_a: 0.02753307057033357\n",
      "Validation Loss p_a: 0.03522243786470166\n",
      "Training   Loss vel: 425.0607373609854\n",
      "Validation Loss vel: 295.78246416364397\n",
      "\n",
      "Time: 772.108s\n",
      "Start of Epoch [14/16]\n",
      "\n",
      "\n",
      "Training batch: 889/889\n",
      "Validation batch: 56/56\n",
      "Training   Loss p_a: 0.027281129233543294\n",
      "Validation Loss p_a: 0.03561067837290466\n",
      "Training   Loss vel: 424.35650258015994\n",
      "Validation Loss vel: 293.8117355619158\n",
      "\n",
      "Time: 772.097s\n",
      "Start of Epoch [15/16]\n",
      "\n",
      "\n",
      "Training batch: 889/889\n",
      "Validation batch: 56/56\n",
      "Training   Loss p_a: 0.027107398821348983\n",
      "Validation Loss p_a: 0.035444154404103756\n",
      "Training   Loss vel: 423.3371689349111\n",
      "Validation Loss vel: 293.6569378716605\n",
      "\n",
      "Time: 771.962s\n",
      "Start of Epoch [16/16]\n",
      "\n",
      "\n",
      "Training batch: 889/889\n",
      "Validation batch: 56/56\n",
      "Training   Loss p_a: 0.026963443514713924\n",
      "Validation Loss p_a: 0.03610945532896689\n",
      "Training   Loss vel: 422.37519170891983\n",
      "Validation Loss vel: 292.9730012076242\n",
      "\n",
      "Time: 771.932s\n",
      "Training time =  12364.836466550827  seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "time_old = start_time\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # try to restore the pre_trained\n",
    "    if restore_model_name is not None:\n",
    "        Load_Directory = Checkpoint_Directory + '20210924/' + restore_model_name\n",
    "               \n",
    "        print(\"Load the model from: {}\".format(restore_model_name))\n",
    "        saver.restore(sess, Load_Directory + '/{}'.format(restore_model_name))\n",
    "        \n",
    "    \n",
    "    # Initial States\n",
    "    timewise_state_val = []\n",
    "    for i in range(len(num_t_units)):\n",
    "        c_t = np.zeros((batch_size * num_notes, num_t_units[i])) \n",
    "        h_t = np.zeros((batch_size * num_notes, num_t_units[i]))\n",
    "        timewise_state_val.append(LSTMStateTuple(h_t, c_t))\n",
    "        \n",
    "    notewise_state_val = []\n",
    "    for i in range(len(num_n_units)):\n",
    "        c_n = np.zeros((batch_size * num_timesteps, num_n_units[i])) \n",
    "        h_n = np.zeros((batch_size * num_timesteps, num_n_units[i]))\n",
    "        notewise_state_val.append(LSTMStateTuple(h_n, c_n))\n",
    "        \n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(epochs):\n",
    "        print('\\rStart of Epoch [%d/%d]'% (epoch + 1, epochs))\n",
    "        print('\\n')\n",
    "\n",
    "        \n",
    "        # Generate batch of training data   \n",
    "        n = 0\n",
    "        for k in training_pieces.keys():\n",
    "            start_old = 0\n",
    "            piece = training_pieces[str(k)]\n",
    "            while start_old < (len(piece) - num_timesteps):\n",
    "                print('\\rTraining batch: %d/%d' % (n + 1, n_train_batches), end='\\r')\n",
    "                batch_input_state_train, start_old = batch.getPieceBatch2(piece, \n",
    "                                                                    num_time_steps = num_timesteps, \n",
    "                                                                    batch_size = batch_size,\n",
    "                                                                    start_old = start_old)    \n",
    "\n",
    "            \n",
    "                # Run Session\n",
    "                feed_dict = {Note_State_Batch: batch_input_state_train, \n",
    "                             output_keep_prob: keep_prob, \n",
    "                             timewise_state: timewise_state_val, \n",
    "                             notewise_state: notewise_state_val}\n",
    "\n",
    "\n",
    "                l_1, l_2, log_likelihood_run, _, velocity_gen_out_run ,note_gen_out_run, Note_State_Batch_result = sess.run(\n",
    "                    [loss_p_a, loss_velocity, log_likelihood, optimizer, output_2, output_3, Note_State_Batch_aligned], \n",
    "                    feed_dict = feed_dict)\n",
    "                \n",
    "                train_loss_p_a_array[epoch, n] = l_1\n",
    "                train_loss_vel_array[epoch, n] = l_2\n",
    "                \n",
    "                n += 1\n",
    "        print('')\n",
    "        \n",
    "        # Generate batch of validation data   \n",
    "        n = 0\n",
    "        for k in validation_pieces.keys():\n",
    "            start_old = 0\n",
    "            piece = validation_pieces[str(k)]\n",
    "            while start_old < (len(piece)- num_timesteps):\n",
    "                print('Validation batch: %d/%d' % (n + 1, n_val_batches), end='\\r')\n",
    "                batch_input_state_val, start_old = batch.getPieceBatch2(piece, \n",
    "                                                                    num_time_steps = num_timesteps, \n",
    "                                                                    batch_size = batch_size, \n",
    "                                                                    start_old = start_old)    \n",
    "\n",
    "                # Run Session\n",
    "                feed_dict = {Note_State_Batch: batch_input_state_val, \n",
    "                             output_keep_prob: keep_prob, \n",
    "                             timewise_state: timewise_state_val, \n",
    "                             notewise_state: notewise_state_val}\n",
    "\n",
    "\n",
    "                l_1, l_2, log_likelihood_run, = sess.run(\n",
    "                    [loss_p_a, loss_velocity, log_likelihood], \n",
    "                    feed_dict = feed_dict)\n",
    "\n",
    "                val_loss_p_a_array[epoch, n] = l_1\n",
    "                val_loss_vel_array[epoch, n] = l_2\n",
    "                n += 1\n",
    "        print('')\n",
    "\n",
    "\n",
    "        time_new = time.time()\n",
    "        duration = time_new - time_old\n",
    "        time_old = time_new\n",
    "        print('Training   Loss p_a: '     + str(np.mean(train_loss_p_a_array[epoch,:])))\n",
    "        print('Validation Loss p_a: '     + str(np.mean(val_loss_p_a_array[epoch,:])))\n",
    "        print('Training   Loss vel: '     + str(np.mean(train_loss_vel_array[epoch,:])))\n",
    "        print('Validation Loss vel: '     + str(np.mean(val_loss_vel_array[epoch,:])))\n",
    "        print('')\n",
    "        print('Time: ' +  str(round(duration, 3)) + 's')\n",
    "\n",
    "        # Periodically save model and loss histories\n",
    "        if (epoch + 1) in epoch_save_list:\n",
    "\n",
    "            model_save_path = Checkpoint_Directory + current_time_str[:-7] + '/{}'.format(save_model_name)\n",
    "            np_save_path = Numpy_Directory + current_time_str[:-7] + '/' \n",
    "            save_path = saver.save(sess, model_save_path)            \n",
    "            try:\n",
    "                os.mkdir(np_save_path) \n",
    "            except:\n",
    "                pass\n",
    "            np.savez(np_save_path + save_model_name + '_array', \n",
    "                     train_loss_p_a_array, \n",
    "                     train_loss_vel_array,\n",
    "                     val_loss_p_a_array, \n",
    "                     val_loss_vel_array,\n",
    "                    ) \n",
    "            for i in range(batch_size):\n",
    "                midi.generate_audio(batch_input_state_train[i:(i+1),:,:,:], \n",
    "                                    Music_Out_Train_Directory + current_time_str[:-7] + '/',\n",
    "                                    'train' + '_epoch_' + str(epoch + 1) + '_batch_' + str(i) + '_true', \n",
    "                                    verbose = False)\n",
    "            prediction = np.concatenate([note_gen_out_run, velocity_gen_out_run, Note_State_Batch_result[:,:,:,3:4]], axis=-1)\n",
    "            for i in range(batch_size):\n",
    "                midi.generate_audio(prediction[i:(i+1),:,:,:], \n",
    "                                    Music_Out_Train_Directory + current_time_str[:-7] + '/',\n",
    "                                    'train' + '_epoch_' + str(epoch + 1) + '_batch_' + str(i) + '_predict', \n",
    "                                    verbose = False)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print('Training time = ', end_time - start_time, ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
